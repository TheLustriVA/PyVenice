[
  {
    "id": "changelog_0_c0452ace",
    "title": "Last week, our engineering team focused heavily on platform stability and reliability along with pre",
    "content": "Last week, our engineering team focused heavily on platform stability and reliability along with preparing a number of new features to release to our beta test group. We look forward to sharing those out over the coming week.AppImages will now render in the UI as they\u2019ve completed vs. waiting for all four to complete for display.Added (i) info buttons to text chats to permit a view of the details of the message (like temperature and top-p).Added sign-up link in the left navigation menu when signed out.Added UI elements that display upscale/enhance images in the chat history. Upscales > 1x will still be automatically downloaded.Added a UI timer to the upscaler message UI to provide some sense of how long the process has been running.Clarified wording on error messages related to capacity on upscale / enhanced images.Fixed a rendering bug related to escaped dollar signs on code blocks in chat.Fixed model specific settings not appropriately applying when selecting \u201cUse these settings\u201dFixed an issue with default settings not resetting across all models as expected.Fixed a bug related to the \u201cdownload all images\u201d button missing on new chats.Deprecated the code specific section of the web app to streamline the web UI.APIUpdated upscale/enhance API to provide more clear error messages when images are outside the bounds of supported sizes.Added support fortop_logprobsparameter as part of the chat completions API.Optimized the performance of the API keys list endpoint used in the app UI and available in the API particularly benefiting users with substantial API traffic.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [
      "deprecation",
      "performance"
    ],
    "is_api_related": true,
    "severity": "high",
    "hash": "f1f694c25590d7457408c673f4116a5d"
  },
  {
    "id": "changelog_1_db974238",
    "title": "API",
    "content": "Given the short week, the team\u2019s engineering efforts this week was primarily focused behind the scenes on reducing model error rates, and on a set of new features that are coming soon.AppAdded a hover action state on images.Fixed a bug preventing the mobile share screen from appearing when with sharing an image on mobile devices.Fixed a bug that prevented horizontal scrolling when viewing complex LaTeX formulas wider than the viewport.Fixed a bug that would cause images to stop displaying after viewing the (i) info details.Disabled negative prompt on HiDream.APIAdded support for multiple image processing to Qwen VL.CharactersAdded new Character setting to hide model reasoning / thinking output for relevant models on character conversations.Updated \u201cReasoning\u201d text to reference \u201cThinking\u201d for character conversations.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [],
    "is_api_related": true,
    "severity": "medium",
    "hash": "efa02438d10c62b785e0af376a45c868"
  },
  {
    "id": "changelog_2_9d0ab694",
    "title": "Pro User? Help us test Simple Mode",
    "content": "It\u2019s been a busy week for our team with 3 major releases, and a slew of updates and bug fixes for you:Simple Mode for Pro UsersVenice\u2026 Enhance any ImageNew Image Model: HiDreamPro User? Help us test Simple ModeWe're about to roll out the biggest upgrade to the Venice's user experience since our launch:Simple Mode.Simple Mode provides a streamlined experience by automatically routing your prompts, eliminating the need to manually select a chat type or model (if you ask for an image, it will just know it, without any conception of \"Image Mode\").We\u2019ve also added the concept of \"image context\", which allows you to build images through  subsequent prompts. We believe for new users, this will dramatically simplify the user experience, making Venice feel and behave more like other generative AI platforms.How can you help?1. Go to your App settings and toggle on Simple Mode. You will see that the model dropdown, and mode selector, will disappear.2. Chat with Venice and try different prompts in natural language. \"Tell me about France\" or \"Create image of France\" etc. Text, web search, image generation, all of it should work automatically.3. Send your experiences and feedback to[email\u00a0protected]. Please include screenshots and videos, or share your chat for things that don't seem to work as expected.We appreciate you taking the time and look forward to hearing your feedback.Venice\u2026 Enhance ImagePro users can nowupscale and enhanceany image.Click on the paperclip or drag and drop an image into the image generation chat.Upscale & Enhance system represents a significant leap beyond traditional pixel-by-pixel methods:\u2022 Use Upscale for accurate enlargements: Use the Upscale feature when you want to maintain the exact style and composition of your image while increasing resolution.\u2022 Use Enhance for creative enhancements: Use the Enhance feature when you want to add details and refinements beyond what's in the original image.HiDream is now available on VeniceRead more about our latest model in ourannouncement tweet.Key FeaturesPrompt adherence- Achieves industry-leading scores on GenEval and DPG benchmarks, outperforming all other open-source models.Text placement- Effective and accurate text generation and placement, making it useful for graphic design purposes.Commercial-friendly- Generated images can be freely used for personal projects, scientific research, and other applications.AppAdded an image generation loading state to make it more clear that the UI is waiting on inference.Added a setting to enable display of message timestamps in the App Settings -FeaturebaseFix crash when editing a chat message and using Space key. -FeaturebaseUpdated the error when documents too large to be processed to be human readable.Refactored context filtering logic to preventYour message is too long for the selected modelerrors when dealing with chat conversations with large histories.Ensure that white space submitted in system prompts sent from the app are preserved all the way to the LLM.Improved error messages when there are issues communicating with Venice\u2019s inference servers.Update the image generation prompt enhancer to ensure messages are constrained to fit within the image prompt limits.APIFixed a regression in streaming responses when invoking tool calling. Added test coverage to avoid future regressions.Enabled support forresponse_formatto 405B and Deepseek. Ensure thinking models don't inject <think> tags into the response when response format is enabled.Return 504 timeouts when non streaming requests timeout. Recommend use of streaming responses when inference is expected to run for longer durations.Remove default `max_tokens` on API calls, permitting inference to use the full context of the LLM unless the user specifies a specificmax_tokensCharactersIntroduced a character avatar popover on larger screens, displaying detailed character information and a quick chat option.Added display of character creation date and creator information on public character profiles.Introduced clearer visual grouping and dividers in character menus.Added a \"View & Rate Character\" menu item for improved access to rating featuresTokenUpdated the token dashboard to fix a few UX issues when used via mobile wallet.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [],
    "is_api_related": true,
    "severity": "high",
    "hash": "58bd69ab14039c3691d69f1ae9405800"
  },
  {
    "id": "changelog_3_ac863f34",
    "title": "App",
    "content": "The big release over the last week was the launch of Venice Search V2 - a complete overhaul on how our search function operates. This was implemented for both our App and API users. Venice search is now:SmarterNow uses AI to generate search queries based on chat context rather than directly searching input text. This results in more contextually relevant information being injected to the conversation, and better overall responses.CleanerOnly displays sources actually referenced in the response, using superscripts. These reference the citations provided below the search.BroaderWe inject a greater number of results with additional information per result into the context.AppReleased Venice Search V2.When switching models, the Top-P and Temperature settings will now automatically default to the optimal setting for that specific model. Additionally, a UI element was added to show what that default for the model is. This should remedy issues with temperatures changing as users move through models resulting in potential gibberish in responses.Adjust the \u201cimage prompt enhancer\u201d to keep its responses below the character limit for image generation.Add a link to the hugging face model card from within the Image Detail view.Add aw/ web searchbanner to responses that have included web search.When using shorten or elaborate, the current selected model will be used for the response, vs. the model that the original message was generated from.Using the space bar will now trigger the \u201caccept\u201d button within confirmation screens.APIReleased Venice Search V2.Added support for purchase of API credits with Crypto via Coinbase Commerce.Add support forstrip_thinking_responsefor reasoning models. This will suppress the<think></think>blocks server side, preventing them from reaching the client. Works in tandem with/no_thinkon the Qwen3 models. API docshave been updatedfor the parameter, and themodel feature suffix docshave also been updated. Satisfies thisFeaturebase.Add support fordisable_thinkingfor reasoning models. This will add/no_thinkin the background, and enablestrip_thinking_response- API docshave been updatedand themodel feature suffixdocs have been updated.Add support forenable_web_citations- This will instruct the LLM to reference the citations it used generating its responses when Web Search is enabled. API docshave been updatedand themodel feature suffixdocs have been updated.Remove 4x option and show \"max\" in its place. This will leverage the above change on the API to allow images that can't 4x upscale to be uploaded. This will still block images that are > 4096 x 4096 since the scale can't be less than 1.When upscaling, if scale is set to 4, dynamically reset it so that the maximum final output size is always less than the max pixel size of our upscaler.Added a model compatibility mapper forgpt-4.1to map toVenice Large / Qwen 3 235B.API Key Creation is now rate limited to 20 new keys per minute with a total of 500 keys per user.CharactersAdded a limit to character names to prevent issues within the UI.Fixed up character display for characters with excessive display information that was previously breaking the page layout.When using the auto-generate character feature, a confirmation box will be presented first to avoid overwriting existing details on accident.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [
      "breaking-change"
    ],
    "is_api_related": true,
    "severity": "high",
    "hash": "dac9341d5843a6e3a102e60654320848"
  },
  {
    "id": "changelog_4_bafb3db4",
    "title": "Model Updates",
    "content": "It\u2019s been a big week of updates with many additional updates and enhancements coming over the next few weeks. Please check out ourbeta group on Discordif you\u2019d like to participate in early testing of our new features.Model UpdatesThank you to the community for all the helpful feedback after our new model paradigm launched. We will always refine our offering and your opinions are immensely helpful. We've decided to make a couple model changes.Llama4 Maverick (aka Venice Large) is being retired May 12thZuck failed us on this one and it needs to go.It has been replaced with the new Qwen3 235B as our Venice Large model.The Venice beta users have been enjoying it, almost universally prefering it to Maverick.Llama 3.2 3B (aka Venice Small) is also being retired.This model had a good run, but a plainly superior option exists now.The new Qwen3 4B will replace it as our Venice Small model.Beta users also very positive on this one. Both of the retiring models will remain in the app+api for 2 weeks under their own names. Maverick will then be taken out to pasture, removed from both app+api. Llama 3.2 3B will leave the app, and remain in API for some time.Deepseek retirement has been postponed to May 30thAdditionally, we\u2019ve heard your feedback RE: Deepseek\u2019s retirement and we\u2019re thinking through options. The retirement for Deepseek has now been moved to May 30th and we\u2019ll provide another update before then.Inpainting DeprecationWe are re-engineering Venice\u2019s in-painting feature set to better serve the use cases we\u2019ve now seen from our users. We are going to deprecate the current version from the app and the API next Monday while we work on the new release.In the interim, we encourage users to experiment with Venice\u2019s \u201cEnhance image\u201d feature which can create neat re-creations of images.AppWe've released an update that should alleviate grammatical errors and missing characters from longer conversations, most notably on 405B. If you continue to see those issues, please use the report conversation feature. Thank you for the existing reports -- they were very helpful in tracking down the issue.Updated theReport Conversationfeature to allow for self reported categorization of the issues. This helps our team identify trends and issues with models faster.Added a Reasoning toggle for reasoning models that support enabling or disabling thinking responses.Added a warning within the chat input for users who have increased temperature into bounds known to create gibberish / garbage responses.Updated the Venice system prompt to reduce likelihood of Venice referencing details about itself in responses unless prompted about Venice.Streamlined the share chat functionality to immediately copy the share URL to the clipboard vs. requiring a second click.Updated the UI to disable the upscale / enhance button if both upscale was turned off and enhance was disabled.Updated the UI to only copy the user\u2019s prompt when copying prompt + images messages.Updated the UI to view image options when viewing image variants in grid format.Fixed a bug where non-pro users were unable to upload documents or images for analysis.Fixed a bug when editing messages containing code blocks that would result in certain characters being improperly escaped.Ensure full EXIF / ICC profile is maintained when using the upscale / enhance feature. Fixes thisFeaturebaserequest which had two[1][2]new reports.APISecurity Notice- Fixed a bug reported via our bug bounty program that permitted API keys marked as inference only be able to manipulate the API key admin endpoint. This would have permitted these inference only keys to add, or remove other API keys. Please validate active API keys created between April 22nd, 2025 and May 7th, 2025 to ensure their validity.Explorer Tier Deprecation -As Venice continues its growth, we\u2019re seeing our API usage reaching all-time highs. Following our announcement last month, we have changed our Pro account API access.Previously, Pro users had unlimited access to our Explorer Tier API with lower rate limits. We have now deprecated the Explorer Tier, and all new Pro subscribers will automatically receive a one-time $10 API credit when they upgrade to Pro \u2013double the credit amount compared to competitors.This credit provides substantial capacity for testing and small applications, with seamless pathways to scale via VVV staking or direct USD payments for larger implementations. This change reflects our API\u2019s maturation from its beta to the enterprise-ready service that developers are increasingly building on the API.Ensure full EXIF / ICC profile is maintained when using the upscale / enhance feature. Fixes thisFeaturebaserequest which had two[1][2]new reports.Add support for OpenAI Embedding names to the Embeddings API via Model Compatibility Mapper.We've released an update that should alleviate grammatical errors and missing characters from longer conversations, most notably on 405B. If you continue to see those issues, please use the report conversation feature. Thank you for the existing reports -- they were very helpful in tracking down the issue.Add support for JSON payload to Upscale / Enhance API - API docs areupdated-Postman example.Fixed a bug that caused thecreatedfield on the OpenAI compatible image generations API to ensure it's coming back as an int and not a float.Fixed a bug causingmodel_feature_suffixfeatures from properly updating their respective flags. Added additional test coverage to ensure this avoids a regression.TokenUpdated the token dashboard coloring.Redirect identifiable mobile wallets to the token dashboard when accessinghttps://venice.aiand hide the PWA installation modal.CharactersUpdated Character UI with imports and rating stats on the primary character cards.Added a UI feature to show which source character a user\u2019s character was cloned from.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [
      "deprecation",
      "security"
    ],
    "is_api_related": true,
    "severity": "high",
    "hash": "4b5fa37e563d819e613a1774ea1b3e54"
  },
  {
    "id": "changelog_5_304cf7fb",
    "title": "New Model Paradigm",
    "content": "New Model ParadigmVenice simplified its model selection with a curated list of LLMs, categorized into five distinct models: Venice Uncensored, Venice Reasoning, Venice Small, Venice Medium, and Venice Large. You can find more details in ourblog post here.The new models include theDolphin Mistral 24B Venice Edition, Venice's most uncensored model ever, and Llama 4 Maverick, a vision-enabled model with a 256K token context window. Several legacy models, including DeepSeek R1, Llama 3.3 70B, and Dolphin 72B, will be retired from the chat interface by May 30. The changes aim to reduce model redundancy, improve user experience, and increase infrastructure scalability.All current models remain available through the Venice API.AppImplemented a substantial revision to search behavior to ensure search results are more effectively integrated into the context.Added support for \u201cEnhance Only\u201d mode via the app. This permits the endpoint to be used solely for enhance without changing the output resolution of the image:Added a prompt for users to permit the browser to persist local storage when their browser storage is becoming full.Fixed a scrolling bug for users with character chats per thisFeaturebase.Added some guidance to the app suggesting using descriptive prompts or the enhance prompt feature when using the Venice SD35 image model.Added in-app guidance when the Temperature setting has been set very high to indicate the LLM may return Gibberish.Added a subscription renewal flow for Crypto user\u2019s who wish to renew their subscription.Fixed a bug where upscale / enhance requests could return blank / black images.Adjusted the pre-processing for in-painting to increase reliability of generation.Fixed a bug where theInput History Navigationsetting in App settings was not properly controlling the feature behavior per thisFeaturebase.CharactersImproved character search UI.Update UI to permit free and anonymous Venice users to see the characters detail modal.APIAdded pricing information to the/modelsendpoint per this request fromFeaturebase. API docs have beenupdated.Increased Token per Minute (TPM) rate limits on medium and large models given Maverick can produce a large number of tokens quickly. API docs have beenupdated.Added support for a 1xscaleparameter to the upscale / enhancement API endpoint. This permits the endpoint to be used solely for enhance without changing the output resolution of the image. Solves thisFeaturebase. API docs have beenupdated.Added a new API route to export billing usage data. API docs have beenupdated.Added support for thelogprobsparameter on our/chat/completionsAPI. API docs have beenupdated.Added a UI to the API settings page to export billing history from the UI.Added support for fractionalscaleparameters to the upscale / enhancement API endpoint.Updated the API to requireapplication/jsonheaders on JSON related endpoints.Return additional detail in error message if a model can not be found to assist user\u2019s in debugging the issue.Added support for Tools / Function Calling to Maverick.Launched an/embeddingsendpoint in beta for Venice beta testers. API docs have beenupdated.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [],
    "is_api_related": true,
    "severity": "medium",
    "hash": "2c57f51d3cdb601b299296982a8c23f1"
  },
  {
    "id": "changelog_6_ac863f34",
    "title": "App",
    "content": "Last week, we complete the migration of our backend infrastructure to our next generation platform. This transition reduces latency and cost and enables support for new types of inference (including video). We look forward to the next round of feature work this new infrastructure will support.AppAdded support forbulk chat deletion. Select the three dots to the right of the chats header to find the option.Swapped out browser confirmation windows with native confirmation windows to allow them to be displayed on mobile crypto wallet browsers (like Coinbase Wallet).Updated our Wallet Connect packages to fix a bug that was causing a notice to pop up prompting to change wallet networks.Added additional delay to the character search to avoid re-rendering while search results are in flight.Updated navigation on character pages making them easier to navigate on mobile.Added support to allow for the \u201cNone\u201d image style to be added to favorites.Fixed a bug that was causing scroll issues in the left nav bar.APIVenice's new upscale enhance mode is now available through the existing upscale API.API docs are availablehere.Postman example cane be foundhere.API pricing for upscale has been updatedhere.Added an OpenAI compatible image generation endpoint. This endpoint supports fewer configuration parameters than our full image endpoint but will work with OpenAI compatible image generation libraries without modification.Docsare updated.Added support forjson_objecttype underresponse_formatfor LLM API requests.Docsare updated.Changed default image model tovenice-sd35to match app default.Return more helpful errors when LLM API requests fail to execute on the runners. This should make debugging complex json_schemas easier to understand.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [],
    "is_api_related": true,
    "severity": "medium",
    "hash": "e27365e2ff677fc5dca274a2a13c77c1"
  },
  {
    "id": "changelog_7_dcbf2ea9",
    "title": "Venice Image Engine V2",
    "content": "It\u2019s been a big week of updates at Venice and we\u2019re excited to share these platform updates with you. The major changes this week include:Venice Image Engine V2Editing of Conversation HistoryLaunch of the Character rating systemMigration of all app inference to our new backendVenice Image Engine V2Venice Image Engine v2 is now live and represents a comprehensive overhaul of our image generation infrastructure, delivering the highest quality results across a range of styles.Venice Image Engine v2 consists of two major components:1.Venice SD35 (New Default model):Custom-configured Stable Diffusion 3.5 engine powered by a Comfy UI workflow backend.2.Upscale & Enhance (Pro only):Completely new upscaling architecture with proprietary enhancement that creatively in-fills new pixels at the higher resolution.Venice SD35Venice implemented substantial improvements to the base Stable Diffusion 3.5 architecture:Natural language understanding:Venice SD35 processes conversational language more effectively, so you can describe images as you would to a human artist instead of using awkward keyword lists.Custom image generation pipeline:A specialized image generation Comfy UI workflow on the backend that delivers superior results through optimized processing techniques that standard implementations don't provide.Let\u2019s compare our new default image model Venice SD35 to our previous default image model Fluently:Upscale and EnhanceThe new Upscale & Enhance system represents a significant leap beyond traditional pixel-by-pixel methods:Use Upscale for accurate enlargements:Use the Upscale feature when you want to maintain the exact style and composition of your image while increasing resolution.Use Enhancer for creative enhancements:Use the Enhance feature when you want to add details and refinements beyond what's in the original image. Adjust the creativity setting based on how much creative liberty you want the AI to take. For consistent results we suggest loading in your original prompt in the prompt field.Combine for professional outputs:Combine both approaches by first generating with Venice SD35, then upscaling, and finally applying a subtle enhancement for the highest quality results. Let\u2019s compare zoomed-in screenshots for the following image.You can read more about this new feature in thisVenice blog post.CharactersAddedcharacter ratingsto public Venice characters. Now, Venice users can help curate the best characters on the platform by adding their ratings and perspective to each character.Closing a character modal with unsaved changes will now prompt the user to avoid losing unsaved work.The save button in the character edit modal is now sticky at the bottom of the window.Character chats are now consolidated into the character section of the left nav bar.AppLaunched the ability for Pro members toedit historyin their conversations. This was one of the most requested items onFeaturebasewith 371 votes. Huge shout out to our beta testing team who worked with us to perfect this feature.Migrated all chat inference from the Venice app to use Venice\u2019s new backend infrastructure. This change should result in increased performance and maintainability as we continue to scale the business.Folders / Characters in the left nav bar are sorted by recent activity.Increased the max response token limit on reasoning models 4x to avoid messages being cut off when reasoning extends for long periods of time / high token counts.Updated our Markdown rendering to better format messages containing $ signs. This fixes a bug where certain responses from the LLMs would be inappropriately displayed as LaTeX formatted text.Added a setting to the App settings panel to remove the warning on external links:Added a progress bar to the UI when deleting chat history \u2014 this makes it more clear what\u2019s going for users with large histories they are deleting.",
    "date": "2025-06-14",
    "category": "Bug Fix",
    "tags": [
      "performance"
    ],
    "is_api_related": true,
    "severity": "high",
    "hash": "7e8d597f4ea8e00bb0648a085ae9637b"
  },
  {
    "id": "changelog_8_994d0662",
    "title": "Characters",
    "content": "Over the last week, the Venice engineering team has been focused on substantial infrastructure overhaul to our backend inference APIs to improve performance and reliability and support additional scale. Additionally, the team has been working on a comprehensive  model curation and testing framework, and preparing to launch a revised image generation infrastructure.These features will manifest themselves into user visible updates over the coming weeks and we are excited release these updates.CharactersRevised our Character moderation system to reduce time to approvals.ModelsAdded support for web search to Llama 3B.AppSupport horizontal scroll for Mathjax containers on mobile.Updated code block and inline code styling for improved readability.Fixeda bugthat was causing white space to be stripped from uploaded documents prior to LLM processing.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [
      "performance"
    ],
    "is_api_related": true,
    "severity": "medium",
    "hash": "f15affa0e3e77c198cd3a37194ce07c2"
  },
  {
    "id": "changelog_9_25ac429f",
    "title": "Models",
    "content": "ModelsMistral 24B is now thedefault Venicemodel for all users, bringing multi-modal capabilities to every one. Llama 70B has been updated to a Pro model.Launched a preview of our new image inference infrastructure to our beta testers.AppImage styles within the image settings are now searchable.AddedConversation Forkingto allow splitting conversations in new directions per thisFeaturebaserequest.Added a \u201cJump to Bottom\u201d mechanism per theFeaturebaserequest.Updated the app background to prevent a white flicker when loading the app.Support pressing Enter to save the name when re-naming a conversation.Update token dashboard to show 2 digits of prevision for staked VVV.Updated authentication logic to programmatically reload authentication tokens if they time out due to the window being backgrounded.Prevent the sidebar from automatically opening when the window is small.Fixed a bug with text settings not properly saving.Update image variant generation to more gracefully handle error cases.Launched a new backend service to support the growth of Venice \u2014 migrated authentication, image generation and upscale to that service. This new service should be more performant and provide Venice a better platform to scale our user continued user growth on.APIAdded thenextEpochBeginskey to theapi_keys/rate_limitsendpoint.Docshave been updated. Solves thisFeaturebaserequest.Addedresponse_formatsupport to Qwen VL in the API.Fixed a bug where messages to Mistral including areasoning_contentnull parameter would throw an error.",
    "date": "2025-06-14",
    "category": "API",
    "tags": [],
    "is_api_related": true,
    "severity": "medium",
    "hash": "79e37712a1cd76be4f59cd50c69a0e93"
  }
]